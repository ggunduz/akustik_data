{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc2cdb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import normalize\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import LSTM, Dense, BatchNormalization, Bidirectional, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35986e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./ESC-50-master/meta/esc50.csv')\n",
    "\n",
    "category_to_class = {\n",
    "    'dog': 'hayvan',\n",
    "    'chirping_birds': 'hayvan',\n",
    "    'vacuum_cleaner': 'arkaplan', \n",
    "    'thunderstorm': 'arkaplan',\n",
    "    'door_wood_knock': 'arkaplan',\n",
    "    'can_opening': 'arkaplan',\n",
    "    'crow': 'arkaplan',\n",
    "    'clapping': 'insan',\n",
    "    'fireworks': 'arkaplan',\n",
    "    'chainsaw': 'arac',\n",
    "    'airplane': 'arac',\n",
    "    'mouse_click': 'arkaplan',\n",
    "    'pouring_water': 'arkaplan',\n",
    "    'train': 'arac',\n",
    "    'sheep': 'hayvan',\n",
    "    'water_drops': 'arkaplan',\n",
    "    'church_bells': 'arkaplan',\n",
    "    'clock_alarm': 'arkaplan',\n",
    "    'keyboard_typing': 'arkaplan',\n",
    "    'wind': 'arkaplan',\n",
    "    'footsteps': 'insan',\n",
    "    'frog': 'arkaplan',\n",
    "    'cow': 'hayvan',\n",
    "    'brushing_teeth': 'arkaplan',\n",
    "    'car_horn': 'arac',\n",
    "    'crackling_fire': 'arkaplan',\n",
    "    'helicopter': 'arac',\n",
    "    'drinking_sipping': 'arkaplan',\n",
    "    'rain': 'arkaplan',\n",
    "    'insects': 'arkaplan',\n",
    "    'laughing': 'insan',\n",
    "    'hen': 'hayvan',\n",
    "    'engine': 'arac',\n",
    "    'breathing': 'insan',\n",
    "    'crying_baby': 'insan', \n",
    "    'hand_saw': 'arac',\n",
    "    'coughing': 'insan',\n",
    "    'glass_breaking': 'arkaplan',\n",
    "    'snoring' : 'insan',\n",
    "    'toilet_flush': 'arkaplan',\n",
    "    'pig': 'hayvan',\n",
    "    'washing_machine': 'arac',\n",
    "    'clock_tick': 'arkaplan',\n",
    "    'sneezing' : 'insan',\n",
    "    'rooster': 'hayvan',\n",
    "    'sea_waves': 'arkaplan',\n",
    "    'siren': 'arac',\n",
    "    'cat': 'hayvan',\n",
    "    'door_wood_creaks': 'arkaplan',\n",
    "    'crickets': 'arkaplan',\n",
    "}\n",
    "\n",
    "df['class'] = df['category'].map(category_to_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d639edf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>fold</th>\n",
       "      <th>target</th>\n",
       "      <th>category</th>\n",
       "      <th>esc10</th>\n",
       "      <th>src_file</th>\n",
       "      <th>take</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1-100032-A-0.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>dog</td>\n",
       "      <td>True</td>\n",
       "      <td>100032</td>\n",
       "      <td>A</td>\n",
       "      <td>hayvan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1-100038-A-14.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>chirping_birds</td>\n",
       "      <td>False</td>\n",
       "      <td>100038</td>\n",
       "      <td>A</td>\n",
       "      <td>hayvan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1-100210-A-36.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>vacuum_cleaner</td>\n",
       "      <td>False</td>\n",
       "      <td>100210</td>\n",
       "      <td>A</td>\n",
       "      <td>arkaplan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1-100210-B-36.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>vacuum_cleaner</td>\n",
       "      <td>False</td>\n",
       "      <td>100210</td>\n",
       "      <td>B</td>\n",
       "      <td>arkaplan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1-101296-A-19.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>thunderstorm</td>\n",
       "      <td>False</td>\n",
       "      <td>101296</td>\n",
       "      <td>A</td>\n",
       "      <td>arkaplan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>5-263831-B-6.wav</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>hen</td>\n",
       "      <td>False</td>\n",
       "      <td>263831</td>\n",
       "      <td>B</td>\n",
       "      <td>hayvan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>5-263902-A-36.wav</td>\n",
       "      <td>5</td>\n",
       "      <td>36</td>\n",
       "      <td>vacuum_cleaner</td>\n",
       "      <td>False</td>\n",
       "      <td>263902</td>\n",
       "      <td>A</td>\n",
       "      <td>arkaplan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>5-51149-A-25.wav</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>footsteps</td>\n",
       "      <td>False</td>\n",
       "      <td>51149</td>\n",
       "      <td>A</td>\n",
       "      <td>insan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>5-61635-A-8.wav</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>sheep</td>\n",
       "      <td>False</td>\n",
       "      <td>61635</td>\n",
       "      <td>A</td>\n",
       "      <td>hayvan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>5-9032-A-0.wav</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>dog</td>\n",
       "      <td>True</td>\n",
       "      <td>9032</td>\n",
       "      <td>A</td>\n",
       "      <td>hayvan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               filename  fold  target        category  esc10  src_file take  \\\n",
       "0      1-100032-A-0.wav     1       0             dog   True    100032    A   \n",
       "1     1-100038-A-14.wav     1      14  chirping_birds  False    100038    A   \n",
       "2     1-100210-A-36.wav     1      36  vacuum_cleaner  False    100210    A   \n",
       "3     1-100210-B-36.wav     1      36  vacuum_cleaner  False    100210    B   \n",
       "4     1-101296-A-19.wav     1      19    thunderstorm  False    101296    A   \n",
       "...                 ...   ...     ...             ...    ...       ...  ...   \n",
       "1995   5-263831-B-6.wav     5       6             hen  False    263831    B   \n",
       "1996  5-263902-A-36.wav     5      36  vacuum_cleaner  False    263902    A   \n",
       "1997   5-51149-A-25.wav     5      25       footsteps  False     51149    A   \n",
       "1998    5-61635-A-8.wav     5       8           sheep  False     61635    A   \n",
       "1999     5-9032-A-0.wav     5       0             dog   True      9032    A   \n",
       "\n",
       "         class  \n",
       "0       hayvan  \n",
       "1       hayvan  \n",
       "2     arkaplan  \n",
       "3     arkaplan  \n",
       "4     arkaplan  \n",
       "...        ...  \n",
       "1995    hayvan  \n",
       "1996  arkaplan  \n",
       "1997     insan  \n",
       "1998    hayvan  \n",
       "1999    hayvan  \n",
       "\n",
       "[2000 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b44c08d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "\n",
    "    file_name = f\"./ESC-50-master/audio/{row['filename']}\"\n",
    "    audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast') \n",
    "    audio_16k = librosa.resample(audio, orig_sr=sample_rate, target_sr=16000)\n",
    "    \n",
    "    x_data.append(audio_16k.copy())\n",
    "    \n",
    "x_data = np.array(x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb1c9b83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       ...,\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['class_categorical'] = df['class'].map({'insan':0, \"hayvan\":1, \"arac\":2, \"arkaplan\":3})\n",
    "y_cat = tf.keras.utils.to_categorical(df['class_categorical'])\n",
    "y_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8dec986f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "from sklearn.preprocessing import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc3b4ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(img):\n",
    "    '''\n",
    "    Normalizes an array \n",
    "    (subtract mean and divide by standard deviation)\n",
    "    '''\n",
    "    eps = 0.001\n",
    "    if np.std(img) != 0:\n",
    "        img = (img - np.mean(img)) / np.std(img)\n",
    "    else:\n",
    "        img = (img - np.mean(img)) / eps\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d41af87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_FEATURES = 64\n",
    "from scipy.fftpack import dct\n",
    "\n",
    "x_train_mfcc_64 = librosa.feature.mfcc(y=x_data, sr=16000, n_mfcc=64)\n",
    "x_train_mfcc_48 = librosa.feature.mfcc(y=x_data, sr=16000, n_mfcc=49)\n",
    "x_train_mfcc_128 = librosa.feature.mfcc(y=x_data, sr=16000, n_mfcc=128)\n",
    "x_train_mfcc_32 = librosa.feature.mfcc(y=x_data, sr=16000, n_mfcc=32)\n",
    "\n",
    "x_train_stft_2048 = librosa.feature.chroma_stft(y = x_data , sr= 16000)\n",
    "x_train_stft_512 = librosa.feature.chroma_stft(y = x_data , sr= 16000, n_fft=512)\n",
    "x_train_stft_256 = librosa.feature.chroma_stft(y = x_data , sr= 16000, n_fft=256)\n",
    "x_train_stft_64 = librosa.feature.chroma_stft(y = x_data , sr= 16000, n_fft=64)\n",
    "x_train_stft_1024 = librosa.feature.chroma_stft(y = x_data , sr= 16000, n_fft=1024)\n",
    "\n",
    "x_train_melspectrogram_512 = librosa.feature.melspectrogram(y=x_data, sr=16000, n_fft = 512)\n",
    "x_train_melspectrogram_1024 = librosa.feature.melspectrogram(y=x_data, sr=16000, n_fft = 1024)\n",
    "x_train_melspectrogram_2048 = librosa.feature.melspectrogram(y=x_data, sr=16000, n_fft = 2048)\n",
    "x_train_melspectrogram_256 = librosa.feature.melspectrogram(y=x_data, sr=16000, n_fft = 256)\n",
    "x_train_melspectrogram_64 = librosa.feature.melspectrogram(y=x_data, sr=16000, n_fft = 64)\n",
    "x_train_melspectrogram_32 = librosa.feature.melspectrogram(y=x_data, sr=16000, n_fft = 32)\n",
    "\n",
    "x_train_dct = dct(x_data)\n",
    "\n",
    "\n",
    "\n",
    "############\n",
    "x_train_mfcc_64_ = normalize(x_train_mfcc_64)\n",
    "x_train_mfcc_48_ = normalize(x_train_mfcc_48)\n",
    "x_train_mfcc_128_ = normalize(x_train_mfcc_128)\n",
    "x_train_mfcc_32_ = normalize(x_train_mfcc_32)\n",
    "\n",
    "x_train_stft_2048_ = normalize(x_train_stft_2048)\n",
    "x_train_stft_512_ = normalize(x_train_stft_512)\n",
    "x_train_stft_1024_ = normalize(x_train_stft_1024)\n",
    "x_train_stft_256_ = normalize(x_train_stft_256)\n",
    "x_train_stft_64_ = normalize(x_train_stft_64)\n",
    "\n",
    "x_train_melspectrogram_512_ = normalize(x_train_melspectrogram_512)\n",
    "x_train_melspectrogram_1024_ = normalize(x_train_melspectrogram_1024)\n",
    "x_train_melspectrogram_2048_ = normalize(x_train_melspectrogram_2048)\n",
    "x_train_melspectrogram_256_ = normalize(x_train_melspectrogram_256)\n",
    "x_train_melspectrogram_64_ = normalize(x_train_melspectrogram_64)\n",
    "x_train_melspectrogram_32_ = normalize(x_train_melspectrogram_32)\n",
    "                                        \n",
    "x_train_dct_ = normalize(x_train_dct)\n",
    "x_train_dct = x_train_dct.resize((x_train_dct.shape[0],1,x_train_dct.shape[1]))\n",
    "x_train_dct_ = x_train_dct_.resize((x_train_dct_.shape[0],1,x_train_dct_.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6c77793b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dd443f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5, 0.5, 0.5, 0, 5, 32, 32, 32, True]\n",
      "[0.5616666666666666, 0.5025, 0.5, 0, 5, 32, 32, 32, False]\n",
      "[0.51, 0.4925, 0.5025, 0, 30, 32, 32, 32, True]\n",
      "[0.565, 0.515, 0.5025, 0, 30, 32, 32, 32, False]\n",
      "[0.49833333333333335, 0.5025, 0.5, 1, 5, 32, 32, 32, True]\n",
      "[0.5, 0.5, 0.5, 1, 5, 32, 32, 32, False]\n",
      "[0.5775, 0.53, 0.4675, 1, 30, 32, 32, 32, True]\n",
      "[0.5, 0.5, 0.5, 1, 30, 32, 32, 32, False]\n",
      "[0.5, 0.5, 0.5, 2, 5, 32, 32, 32, True]\n",
      "[0.5, 0.5, 0.5, 2, 5, 32, 32, 32, False]\n",
      "[0.5333333333333333, 0.495, 0.5025, 2, 30, 32, 32, 32, True]\n",
      "[0.5308333333333334, 0.5, 0.505, 2, 30, 32, 32, 32, False]\n",
      "[0.5, 0.5, 0.5, 3, 5, 32, 32, 32, True]\n",
      "[0.5, 0.5, 0.5, 3, 5, 32, 32, 32, False]\n",
      "[0.575, 0.495, 0.5025, 3, 30, 32, 32, 32, True]\n",
      "[0.5358333333333334, 0.495, 0.5025, 3, 30, 32, 32, 32, False]\n",
      "[0.5241666666666667, 0.5075, 0.4775, 4, 5, 32, 32, 32, True]\n",
      "[0.5208333333333334, 0.51, 0.51, 4, 5, 32, 32, 32, False]\n",
      "[0.5, 0.5, 0.5, 4, 30, 32, 32, 32, True]\n",
      "[0.6175, 0.4825, 0.4975, 4, 30, 32, 32, 32, False]\n",
      "[0.5, 0.5, 0.5, 5, 5, 32, 32, 32, True]\n",
      "[0.5283333333333333, 0.5025, 0.4875, 5, 5, 32, 32, 32, False]\n",
      "[0.5316666666666666, 0.5075, 0.5075, 5, 30, 32, 32, 32, True]\n",
      "[0.5808333333333333, 0.4875, 0.5075, 5, 30, 32, 32, 32, False]\n",
      "[0.5, 0.5, 0.5, 6, 5, 32, 32, 32, True]\n",
      "[0.5108333333333334, 0.5, 0.505, 6, 5, 32, 32, 32, False]\n",
      "[0.5, 0.5, 0.5, 6, 30, 32, 32, 32, True]\n",
      "[0.5316666666666666, 0.4425, 0.48, 6, 30, 32, 32, 32, False]\n",
      "[0.5, 0.5, 0.5, 7, 5, 32, 32, 32, True]\n",
      "[0.5025, 0.5, 0.5, 7, 5, 32, 32, 32, False]\n",
      "[0.5, 0.5, 0.5, 7, 30, 32, 32, 32, True]\n",
      "[0.5, 0.5, 0.5, 7, 30, 32, 32, 32, False]\n",
      "[0.5, 0.5, 0.5, 8, 5, 32, 32, 32, True]\n",
      "[0.57, 0.4975, 0.5, 8, 5, 32, 32, 32, False]\n",
      "[0.5, 0.5, 0.5, 8, 30, 32, 32, 32, True]\n",
      "[0.555, 0.485, 0.475, 8, 30, 32, 32, 32, False]\n",
      "[0.5, 0.5, 0.5, 9, 5, 32, 32, 32, True]\n",
      "[0.5583333333333333, 0.5275, 0.4875, 9, 5, 32, 32, 32, False]\n",
      "[0.5016666666666667, 0.5, 0.4975, 9, 30, 32, 32, 32, True]\n",
      "[0.5475, 0.52, 0.485, 9, 30, 32, 32, 32, False]\n",
      "[0.5, 0.5, 0.5, 10, 5, 32, 32, 32, True]\n",
      "[0.5016666666666667, 0.5, 0.5, 10, 5, 32, 32, 32, False]\n",
      "[0.5025, 0.5025, 0.5, 10, 30, 32, 32, 32, True]\n",
      "[0.5291666666666667, 0.5125, 0.5, 10, 30, 32, 32, 32, False]\n",
      "[0.5225, 0.485, 0.5075, 11, 5, 32, 32, 32, True]\n",
      "[0.5233333333333333, 0.4875, 0.49, 11, 5, 32, 32, 32, False]\n",
      "[0.5108333333333334, 0.5025, 0.505, 11, 30, 32, 32, 32, True]\n",
      "[0.5758333333333333, 0.5, 0.505, 11, 30, 32, 32, 32, False]\n",
      "[0.5, 0.5, 0.5, 12, 5, 32, 32, 32, True]\n",
      "[0.5358333333333334, 0.5125, 0.505, 12, 5, 32, 32, 32, False]\n",
      "[0.5, 0.5, 0.5, 12, 30, 32, 32, 32, True]\n",
      "[0.5058333333333334, 0.5, 0.49, 12, 30, 32, 32, 32, False]\n",
      "[0.545, 0.53, 0.535, 13, 5, 32, 32, 32, True]\n",
      "[0.5, 0.5, 0.5, 13, 5, 32, 32, 32, False]\n",
      "[0.5, 0.5, 0.5, 13, 30, 32, 32, 32, True]\n",
      "[0.5, 0.5, 0.5, 13, 30, 32, 32, 32, False]\n",
      "[0.5, 0.5, 0.5, 14, 5, 32, 32, 32, True]\n",
      "[0.5, 0.5, 0.5, 14, 5, 32, 32, 32, False]\n",
      "[0.5, 0.5, 0.5, 14, 30, 32, 32, 32, True]\n",
      "[0.5, 0.5, 0.5, 14, 30, 32, 32, 32, False]\n",
      "[0.5125, 0.5125, 0.5125, 16, 5, 32, 32, 32, True]\n",
      "[0.5216666666666666, 0.5025, 0.5275, 16, 5, 32, 32, 32, False]\n",
      "[0.625, 0.5775, 0.55, 16, 30, 32, 32, 32, True]\n",
      "[0.6175, 0.54, 0.57, 16, 30, 32, 32, 32, False]\n",
      "[0.605, 0.59, 0.5425, 17, 5, 32, 32, 32, True]\n",
      "[0.6016666666666667, 0.5425, 0.5325, 17, 5, 32, 32, 32, False]\n",
      "[0.625, 0.585, 0.5775, 17, 30, 32, 32, 32, True]\n",
      "[0.64, 0.5375, 0.5475, 17, 30, 32, 32, 32, False]\n",
      "[0.5, 0.5, 0.5, 18, 5, 32, 32, 32, True]\n",
      "[0.5, 0.5, 0.5, 18, 5, 32, 32, 32, False]\n",
      "[0.5, 0.5, 0.5, 18, 30, 32, 32, 32, True]\n",
      "[0.5, 0.5, 0.5, 18, 30, 32, 32, 32, False]\n",
      "[0.5058333333333334, 0.4975, 0.485, 19, 5, 32, 32, 32, True]\n",
      "[0.5641666666666667, 0.5325, 0.5225, 19, 5, 32, 32, 32, False]\n",
      "[0.5625, 0.5325, 0.55, 19, 30, 32, 32, 32, True]\n",
      "[0.6883333333333334, 0.535, 0.5475, 19, 30, 32, 32, 32, False]\n",
      "[0.5, 0.5, 0.5, 20, 5, 32, 32, 32, True]\n",
      "[0.5566666666666666, 0.5125, 0.5125, 20, 5, 32, 32, 32, False]\n",
      "[0.5025, 0.5, 0.5025, 20, 30, 32, 32, 32, True]\n",
      "[0.6291666666666667, 0.505, 0.5, 20, 30, 32, 32, 32, False]\n",
      "[0.54, 0.52, 0.505, 21, 5, 32, 32, 32, True]\n",
      "[0.5666666666666667, 0.51, 0.5025, 21, 5, 32, 32, 32, False]\n",
      "[0.5333333333333333, 0.5, 0.5025, 21, 30, 32, 32, 32, True]\n",
      "[0.5033333333333333, 0.505, 0.5025, 21, 30, 32, 32, 32, False]\n",
      "[0.5, 0.5, 0.5, 22, 5, 32, 32, 32, True]\n",
      "[0.5008333333333334, 0.5, 0.5, 22, 5, 32, 32, 32, False]\n",
      "[0.5058333333333334, 0.495, 0.5025, 22, 30, 32, 32, 32, True]\n",
      "[0.5366666666666666, 0.48, 0.49, 22, 30, 32, 32, 32, False]\n",
      "[0.5, 0.5, 0.5, 23, 5, 32, 32, 32, True]\n",
      "[0.5025, 0.5, 0.4975, 23, 5, 32, 32, 32, False]\n",
      "[0.5, 0.5, 0.5, 23, 30, 32, 32, 32, True]\n",
      "[0.5, 0.5, 0.5, 23, 30, 32, 32, 32, False]\n",
      "[0.5, 0.5, 0.5, 24, 5, 32, 32, 32, True]\n",
      "[0.5675, 0.53, 0.5275, 24, 5, 32, 32, 32, False]\n",
      "[0.5, 0.5, 0.5, 24, 30, 32, 32, 32, True]\n",
      "[0.605, 0.525, 0.5075, 24, 30, 32, 32, 32, False]\n",
      "[0.5, 0.5, 0.5, 25, 5, 32, 32, 32, True]\n",
      "[0.5, 0.5, 0.5, 25, 5, 32, 32, 32, False]\n",
      "[0.5, 0.5, 0.5, 25, 30, 32, 32, 32, True]\n",
      "[0.5, 0.5, 0.5, 25, 30, 32, 32, 32, False]\n",
      "[0.5, 0.5, 0.5, 26, 5, 32, 32, 32, True]\n",
      "[0.5008333333333334, 0.5, 0.5, 26, 5, 32, 32, 32, False]\n",
      "[0.5, 0.5, 0.5, 26, 30, 32, 32, 32, True]\n",
      "[0.5008333333333334, 0.5, 0.5, 26, 30, 32, 32, 32, False]\n",
      "[0.5, 0.5, 0.5, 27, 5, 32, 32, 32, True]\n",
      "[0.5, 0.5, 0.5, 27, 5, 32, 32, 32, False]\n",
      "[0.5, 0.5, 0.5, 27, 30, 32, 32, 32, True]\n",
      "[0.5, 0.5, 0.5, 27, 30, 32, 32, 32, False]\n",
      "[0.5, 0.5, 0.5, 28, 5, 32, 32, 32, True]\n",
      "[0.5033333333333333, 0.5, 0.5, 28, 5, 32, 32, 32, False]\n",
      "[0.5, 0.5, 0.5, 28, 30, 32, 32, 32, True]\n",
      "[0.5008333333333334, 0.495, 0.5, 28, 30, 32, 32, 32, False]\n",
      "[0.5, 0.5, 0.5, 29, 5, 32, 32, 32, True]\n",
      "[0.515, 0.5, 0.51, 29, 5, 32, 32, 32, False]\n",
      "[0.5, 0.5, 0.5, 29, 30, 32, 32, 32, True]\n",
      "[0.5, 0.5, 0.5, 29, 30, 32, 32, 32, False]\n",
      "[0.5, 0.5, 0.5, 30, 5, 32, 32, 32, True]\n",
      "[0.5, 0.5, 0.5, 30, 5, 32, 32, 32, False]\n",
      "[0.5, 0.5, 0.5, 30, 30, 32, 32, 32, True]\n",
      "[0.5058333333333334, 0.495, 0.505, 30, 30, 32, 32, 32, False]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import *\n",
    "\n",
    "feat_type = 'mfcc'\n",
    "NUM_FEATURES = 64\n",
    "\n",
    "names = [\n",
    "    'MFCC-64',\n",
    "    'MFCC-48',\n",
    "    'MFCC-128',\n",
    "    'MFCC-32',\n",
    "    'STFT-2048',\n",
    "    'STFT-512',\n",
    "    'STFT-256',\n",
    "    'STFT-64',\n",
    "    'STFT-1024',\n",
    "    'Mel-Spectrogram-512',\n",
    "    'Mel-Spectrogram-1024',\n",
    "    'Mel-Spectrogram-2048',\n",
    "    'Mel-Spectrogram-256',\n",
    "    'Mel-Spectrogram-64',\n",
    "    'Mel-Spectrogram-32',\n",
    "    'Discrete Cosine Transform',\n",
    "    'MFCC-64-normalized',\n",
    "    'MFCC-48-normalized',\n",
    "    'MFCC-128-normalized',\n",
    "    'MFCC-32-normalized',\n",
    "    'STFT-2048-normalized',\n",
    "    'STFT-512-normalized',\n",
    "    'STFT-256-normalized',\n",
    "    'STFT-64-normalized',\n",
    "    'STFT-1024-normalized',\n",
    "    'Mel-Spectrogram-512-normalized',\n",
    "    'Mel-Spectrogram-1024-normalized',\n",
    "    'Mel-Spectrogram-2048-normalized',\n",
    "    'Mel-Spectrogram-256-normalized',\n",
    "    'Mel-Spectrogram-64-normalized',\n",
    "    'Mel-Spectrogram-32-normalized',   \n",
    "    'Discrete Cosine Transform-normalized',\n",
    "]\n",
    "\n",
    "report = []\n",
    "\n",
    "for n, dat_o in enumerate([\n",
    "        x_train_mfcc_64,\n",
    "        x_train_mfcc_48,\n",
    "        x_train_mfcc_128,\n",
    "        x_train_mfcc_32,    \n",
    "        x_train_stft_2048,\n",
    "        x_train_stft_512,\n",
    "        x_train_stft_256,\n",
    "        x_train_stft_64,\n",
    "        x_train_stft_1024,\n",
    "        x_train_melspectrogram_512,\n",
    "        x_train_melspectrogram_1024,\n",
    "        x_train_melspectrogram_2048,\n",
    "        x_train_melspectrogram_256,\n",
    "        x_train_melspectrogram_64,\n",
    "        x_train_melspectrogram_32,\n",
    "        x_train_dct,\n",
    "        x_train_mfcc_64_,\n",
    "        x_train_mfcc_48_,\n",
    "        x_train_mfcc_128_,\n",
    "        x_train_mfcc_32_,\n",
    "        x_train_stft_2048_,\n",
    "        x_train_stft_512_,\n",
    "        x_train_stft_256_,\n",
    "        x_train_stft_64_,\n",
    "        x_train_stft_1024_,\n",
    "        x_train_melspectrogram_512_,\n",
    "        x_train_melspectrogram_1024_,\n",
    "        x_train_melspectrogram_2048_,\n",
    "        x_train_melspectrogram_256_,\n",
    "        x_train_melspectrogram_64_,\n",
    "        x_train_melspectrogram_32_,\n",
    "        x_train_dct_,\n",
    "           ]):\n",
    "    \n",
    "    for n_lstm in [5,30]:\n",
    "     for d1 in [32]:\n",
    "      for d2 in [32]:\n",
    "       for bs in [32]:\n",
    "        for rs in [True, False]:\n",
    "        \n",
    "            try:\n",
    "                if rs:\n",
    "                    dat = dat_o.reshape((dat_o.shape[0], dat_o.shape[2], dat_o.shape[1]))\n",
    "                else:\n",
    "                    dat = dat_o.copy()\n",
    "            except:\n",
    "                continue\n",
    "                \n",
    "            ind_test = df[df['fold']==5].index.tolist()\n",
    "            ind_val = df[df['fold']==4].index.tolist()\n",
    "            ind_tr = df[df['fold'].isin([1,2,3])].index.tolist()\n",
    "\n",
    "            \n",
    "            x_val = dat[ind_val]\n",
    "            x_train = dat[ind_tr]\n",
    "            x_test = dat[ind_test]\n",
    "\n",
    "            y_train = y_cat[ind_tr]\n",
    "            y_val = y_cat[ind_val]\n",
    "            y_test = y_cat[ind_test]\n",
    "\n",
    "\n",
    "            yoff = np.zeros(len(x_test))\n",
    "            \n",
    "            inp = Input(shape=(x_val.shape[1], x_val.shape[2]))\n",
    "            x1 = LSTM(n_lstm, return_sequences = True)(inp)\n",
    "            x1 = LSTM(n_lstm)(x1)\n",
    "            x1 = Dense(d1,activation='relu')(x1)\n",
    "            x1 = Dense(d2,activation='relu')(x1)\n",
    "            out = Dense(y_cat.shape[1],activation='softmax')(x1)\n",
    "            model = Model(inputs=inp, outputs=out)\n",
    "\n",
    "            es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, verbose = 0)\n",
    "            optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001)\n",
    "            model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "            history = model.fit(x_train, y_train, batch_size=bs, epochs=500, validation_data=(x_val, y_val), verbose = 0, callbacks = [es])\n",
    "\n",
    "            pred_train = model.predict(x_train)\n",
    "            pred_val = model.predict(x_val)\n",
    "            pred_test = model.predict(x_test)\n",
    "\n",
    "            curacc_train = accuracy_score(np.argmax(y_train, axis=1), np.argmax(pred_train, axis=1))\n",
    "            curacc_val = accuracy_score(np.argmax(y_val, axis=1), np.argmax(pred_val, axis=1))\n",
    "            curacc_test = accuracy_score(np.argmax(y_test, axis=1), np.argmax(pred_test, axis=1))\n",
    "\n",
    "            yoff = np.argmax(pred_val, axis=1)\n",
    "            #print([curacc_train, curacc_val])\n",
    "\n",
    "            name = names[n]\n",
    "            \n",
    "            r = {}\n",
    "            r['name'] = name\n",
    "            r['accuracy_test'] = curacc_test\n",
    "            r['accuracy_val'] = curacc_val\n",
    "            r['accuracy_train'] = curacc_train\n",
    "            \n",
    "            r['num_LSTM'] = n_lstm\n",
    "            r['num_Dense_1'] = d1\n",
    "            r['num_Dense_2'] = d2\n",
    "            r['batch_size'] = bs\n",
    "            \n",
    "            r['reshape'] = rs\n",
    "            \n",
    "            report.append(r.copy())\n",
    "            \n",
    "            print([curacc_train, curacc_val, curacc_test, n, n_lstm, d1, d2 , bs, rs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "58ca99b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>accuracy_test</th>\n",
       "      <th>accuracy_val</th>\n",
       "      <th>accuracy_train</th>\n",
       "      <th>num_LSTM</th>\n",
       "      <th>num_Dense_1</th>\n",
       "      <th>num_Dense_2</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>reshape</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MFCC-48</td>\n",
       "      <td>0.4675</td>\n",
       "      <td>0.5300</td>\n",
       "      <td>0.577500</td>\n",
       "      <td>30</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>STFT-1024</td>\n",
       "      <td>0.4750</td>\n",
       "      <td>0.4850</td>\n",
       "      <td>0.555000</td>\n",
       "      <td>30</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>STFT-2048</td>\n",
       "      <td>0.4775</td>\n",
       "      <td>0.5075</td>\n",
       "      <td>0.524167</td>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>STFT-256</td>\n",
       "      <td>0.4800</td>\n",
       "      <td>0.4425</td>\n",
       "      <td>0.531667</td>\n",
       "      <td>30</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Mel-Spectrogram-512</td>\n",
       "      <td>0.4850</td>\n",
       "      <td>0.5200</td>\n",
       "      <td>0.547500</td>\n",
       "      <td>30</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>MFCC-48-normalized</td>\n",
       "      <td>0.5475</td>\n",
       "      <td>0.5375</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>30</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>MFCC-64-normalized</td>\n",
       "      <td>0.5500</td>\n",
       "      <td>0.5775</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>30</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>MFCC-32-normalized</td>\n",
       "      <td>0.5500</td>\n",
       "      <td>0.5325</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>30</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>MFCC-64-normalized</td>\n",
       "      <td>0.5700</td>\n",
       "      <td>0.5400</td>\n",
       "      <td>0.617500</td>\n",
       "      <td>30</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>MFCC-48-normalized</td>\n",
       "      <td>0.5775</td>\n",
       "      <td>0.5850</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>30</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   name  accuracy_test  accuracy_val  accuracy_train  \\\n",
       "6               MFCC-48         0.4675        0.5300        0.577500   \n",
       "35            STFT-1024         0.4750        0.4850        0.555000   \n",
       "16            STFT-2048         0.4775        0.5075        0.524167   \n",
       "27             STFT-256         0.4800        0.4425        0.531667   \n",
       "39  Mel-Spectrogram-512         0.4850        0.5200        0.547500   \n",
       "..                  ...            ...           ...             ...   \n",
       "67   MFCC-48-normalized         0.5475        0.5375        0.640000   \n",
       "62   MFCC-64-normalized         0.5500        0.5775        0.625000   \n",
       "74   MFCC-32-normalized         0.5500        0.5325        0.562500   \n",
       "63   MFCC-64-normalized         0.5700        0.5400        0.617500   \n",
       "66   MFCC-48-normalized         0.5775        0.5850        0.625000   \n",
       "\n",
       "    num_LSTM  num_Dense_1  num_Dense_2  batch_size  reshape  \n",
       "6         30           32           32          32     True  \n",
       "35        30           32           32          32    False  \n",
       "16         5           32           32          32     True  \n",
       "27        30           32           32          32    False  \n",
       "39        30           32           32          32    False  \n",
       "..       ...          ...          ...         ...      ...  \n",
       "67        30           32           32          32    False  \n",
       "62        30           32           32          32     True  \n",
       "74        30           32           32          32     True  \n",
       "63        30           32           32          32    False  \n",
       "66        30           32           32          32     True  \n",
       "\n",
       "[120 rows x 9 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(report).sort_values('accuracy_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4a20da",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n, dat in enumerate([x_train_mfcc_64,\n",
    "           x_train_mfcc_128,\n",
    "           x_train_mfcc_32,\n",
    "           x_train_stft_2048,\n",
    "           x_train_stft_512,\n",
    "           x_train_stft_1024,\n",
    "           x_train_melspectrogram_512,\n",
    "           x_train_melspectrogram_1024,\n",
    "           x_train_melspectrogram_2048,\n",
    "           x_train_dct\n",
    "           ]):\n",
    "    \n",
    "    print(dat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef183bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold in df['fold'].unique():\n",
    "    \n",
    "    ind_val = df[df['fold']==fold].index\n",
    "    ind_tr = df[df['fold']!=fold].index\n",
    "    \n",
    "    x_val = x[ind_val]\n",
    "    x_train = x[ind_tr]\n",
    "    \n",
    "    y_train = y_cat[ind_tr]\n",
    "    y_val = y_cat[ind_val]\n",
    "\n",
    "\n",
    "    if transpose:\n",
    "        x_train_copy = x_train.reshape((x_train.shape[0], x_train.shape[2], x_train.shape[1]))\n",
    "        x_val_copy = x_val.reshape((x_val.shape[0], x_val.shape[2], x_val.shape[1]))\n",
    "        x_test_copy = x_test.reshape((x_test.shape[0], x_test.shape[2], x_test.shape[1]))\n",
    "\n",
    "    else:\n",
    "        x_train_copy = x_train.copy()\n",
    "        x_val_copy = x_val.copy()\n",
    "        x_test_copy = x_test.copy()\n",
    "\n",
    "    tf.random.set_seed(3)\n",
    "\n",
    "\n",
    "    inp = Input(shape=(x_train_copy.shape[1],x_train_copy.shape[2]))\n",
    "\n",
    "    if mitr == 0:\n",
    "        #x = Conv1D(25, kernel_size=2)(inp)\n",
    "        x = Conv1D(64,5,strides=1,activation=\"relu\",)(inp)\n",
    "        x = Attention()([x,x])\n",
    "        if ump:\n",
    "            x = MaxPooling1D()(x)\n",
    "        x = Bidirectional(LSTM(l))(x)\n",
    "        x = Dense(d,activation='relu')(x)\n",
    "        x = Dense(d,activation='relu')(x)\n",
    "\n",
    "    elif mitr == 1:\n",
    "        #x = Conv1D(25, kernel_size=2)(inp)\n",
    "        x = LSTM(l,return_sequences= True )(inp)\n",
    "        if ump:\n",
    "            x = MaxPooling1D()(x)\n",
    "        x = LSTM(l)(x)\n",
    "        x = Dense(d,activation='relu')(x)\n",
    "        x = Dense(d,activation='relu')(x)\n",
    "\n",
    "    elif mitr == 2:\n",
    "        #x = Conv1D(25, kernel_size=2)(inp)\n",
    "        x = Bidirectional(LSTM(l,return_sequences= True ))(inp)\n",
    "        if ump:\n",
    "            x = MaxPooling1D()(x)\n",
    "        x = Bidirectional(LSTM(l))(x)\n",
    "        x = Dense(d,activation='relu')(x)\n",
    "        x = Dense(d,activation='relu')(x)\n",
    "\n",
    "    elif mitr == 3:\n",
    "        #x = Conv1D(25, kernel_size=2)(inp)\n",
    "        x = Bidirectional(LSTM(l,return_sequences= True ))(inp)\n",
    "        x = Attention()([x,x])\n",
    "        if ump:\n",
    "            x = MaxPooling1D()(x)\n",
    "        x = Bidirectional(LSTM(l))(x)\n",
    "        x = Dense(d,activation='relu')(x)\n",
    "        x = Dense(d,activation='relu')(x)\n",
    "\n",
    "\n",
    "    out = Dense(y_cat.shape[1],activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=inp, outputs=out)\n",
    "\n",
    "    es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, verbose = 0)\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate = lr)\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "    history = model.fit(x_train_copy, y_train, batch_size=bs, epochs=500, validation_data=(x_val_copy, y_val), verbose =0, callbacks = [es])\n",
    "\n",
    "\n",
    "    pred_train = model.predict(x_train_copy)\n",
    "    pred_val = model.predict(x_val_copy)\n",
    "    pred_test = model.predict(x_test_copy)\n",
    "\n",
    "    curacc_train = accuracy_score(np.argsort(y_train,axis=1)[:,-1], np.argsort(pred_train,axis=1)[:,-1])\n",
    "    curacc_val = accuracy_score(np.argsort(y_val,axis=1)[:,-1], np.argsort(pred_val,axis=1)[:,-1])\n",
    "    curacc_test = accuracy_score(np.argsort(y_test,axis=1)[:,-1], np.argsort(pred_test,axis=1)[:,-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cc4f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "import tensorflow as tf\n",
    "    \n",
    "from sklearn.metrics import *\n",
    "bestacc = 0\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import LSTM, Dense, Input, Conv1D, AveragePooling1D, Attention\n",
    "from tensorflow.keras.optimizers import *\n",
    "        \n",
    "\n",
    "\n",
    "for l in [50,100,200]:\n",
    "  for d in [32]:\n",
    "   for bs in [4,16]:\n",
    "    for lr in [0.001]:\n",
    "       for transpose in [ False]:\n",
    "        for bn in [False]:\n",
    "         for mitr in range(4):\n",
    "          for ump in [True,False]:\n",
    "            for split_name, split_df in [\n",
    "                                        ('mfcc_normalized', normalized_padded_inputs),\n",
    "                                        ('spectrogram_normalized', normalized_padded_inputs_spec),\n",
    "                                        ]:\n",
    "\n",
    "\n",
    "                x_train = split_df[tr]\n",
    "                x_val = split_df[val]\n",
    "                x_test = split_df[test]\n",
    "\n",
    "                y_train = y_cat[tr]\n",
    "                y_val = y_cat[val]\n",
    "                y_test = y_cat[test]\n",
    "    \n",
    "\n",
    "                if transpose:\n",
    "                    x_train_copy = x_train.reshape((x_train.shape[0], x_train.shape[2], x_train.shape[1]))\n",
    "                    x_val_copy = x_val.reshape((x_val.shape[0], x_val.shape[2], x_val.shape[1]))\n",
    "                    x_test_copy = x_test.reshape((x_test.shape[0], x_test.shape[2], x_test.shape[1]))\n",
    "\n",
    "                else:\n",
    "                    x_train_copy = x_train.copy()\n",
    "                    x_val_copy = x_val.copy()\n",
    "                    x_test_copy = x_test.copy()\n",
    "\n",
    "                tf.random.set_seed(3)\n",
    "\n",
    "                \n",
    "                inp = Input(shape=(x_train_copy.shape[1],x_train_copy.shape[2]))\n",
    "\n",
    "                if mitr == 0:\n",
    "                    #x = Conv1D(25, kernel_size=2)(inp)\n",
    "                    x = Conv1D(64,5,strides=1,activation=\"relu\",)(inp)\n",
    "                    x = Attention()([x,x])\n",
    "                    if ump:\n",
    "                        x = MaxPooling1D()(x)\n",
    "                    x = Bidirectional(LSTM(l))(x)\n",
    "                    x = Dense(d,activation='relu')(x)\n",
    "                    x = Dense(d,activation='relu')(x)\n",
    "\n",
    "                elif mitr == 1:\n",
    "                    #x = Conv1D(25, kernel_size=2)(inp)\n",
    "                    x = LSTM(l,return_sequences= True )(inp)\n",
    "                    if ump:\n",
    "                        x = MaxPooling1D()(x)\n",
    "                    x = LSTM(l)(x)\n",
    "                    x = Dense(d,activation='relu')(x)\n",
    "                    x = Dense(d,activation='relu')(x)\n",
    "                    \n",
    "                elif mitr == 2:\n",
    "                    #x = Conv1D(25, kernel_size=2)(inp)\n",
    "                    x = Bidirectional(LSTM(l,return_sequences= True ))(inp)\n",
    "                    if ump:\n",
    "                        x = MaxPooling1D()(x)\n",
    "                    x = Bidirectional(LSTM(l))(x)\n",
    "                    x = Dense(d,activation='relu')(x)\n",
    "                    x = Dense(d,activation='relu')(x)\n",
    "                    \n",
    "                elif mitr == 3:\n",
    "                    #x = Conv1D(25, kernel_size=2)(inp)\n",
    "                    x = Bidirectional(LSTM(l,return_sequences= True ))(inp)\n",
    "                    x = Attention()([x,x])\n",
    "                    if ump:\n",
    "                        x = MaxPooling1D()(x)\n",
    "                    x = Bidirectional(LSTM(l))(x)\n",
    "                    x = Dense(d,activation='relu')(x)\n",
    "                    x = Dense(d,activation='relu')(x)\n",
    "\n",
    "                    \n",
    "                out = Dense(y_cat.shape[1],activation='softmax')(x)\n",
    "\n",
    "                model = Model(inputs=inp, outputs=out)\n",
    "\n",
    "                es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, verbose = 0)\n",
    "\n",
    "                optimizer = tf.keras.optimizers.Adam(learning_rate = lr)\n",
    "                model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "                history = model.fit(x_train_copy, y_train, batch_size=bs, epochs=500, validation_data=(x_val_copy, y_val), verbose =0, callbacks = [es])\n",
    "\n",
    "\n",
    "                pred_train = model.predict(x_train_copy)\n",
    "                pred_val = model.predict(x_val_copy)\n",
    "                pred_test = model.predict(x_test_copy)\n",
    "\n",
    "                curacc_train = accuracy_score(np.argsort(y_train,axis=1)[:,-1], np.argsort(pred_train,axis=1)[:,-1])\n",
    "                curacc_val = accuracy_score(np.argsort(y_val,axis=1)[:,-1], np.argsort(pred_val,axis=1)[:,-1])\n",
    "                curacc_test = accuracy_score(np.argsort(y_test,axis=1)[:,-1], np.argsort(pred_test,axis=1)[:,-1])\n",
    "\n",
    "                model.save('my_model.h5')\n",
    "\n",
    "                import os\n",
    "\n",
    "                def get_size(path):\n",
    "                    size = os.path.getsize(path)\n",
    "                    if size < 1024:\n",
    "                        return f\"{size} bytes\"\n",
    "                    elif size < 1024*1024:\n",
    "                        return f\"{round(size/1024, 2)} KB\"\n",
    "                    elif size < 1024*1024*1024:\n",
    "                        return f\"{round(size/(1024*1024), 2)} MB\"\n",
    "                    elif size < 1024*1024*1024*1024:\n",
    "                        return f\"{round(size/(1024*1024*1024), 2)} GB\"\n",
    "\n",
    "                \n",
    "\n",
    "                print('______')\n",
    "                print(['Train:', curacc_train, 'Val:', curacc_val, 'Test:', curacc_test])\n",
    "                cm_val = confusion_matrix(np.argmax(y_val,axis=1), np.argmax(pred_val,axis=1))\n",
    "                #print(cm_val)\n",
    "\n",
    "                cm_test = confusion_matrix(np.argmax(y_test,axis=1), np.argmax(pred_test,axis=1))\n",
    "                #print(cm_test)\n",
    "                print([split_name, mitr, ump, l, d, bs, lr , outact, transpose, bn, 'Model Size:', get_size('my_model.h5')])\n",
    "   \n",
    "'''\n",
    "['Train:', 0.6758333333333333, 'Val:', 0.5725, 'Test:', 0.59]\n",
    "['mfcc_normalized', 0, True, 50, 32, 4, 0.001, 'softmax', False, False, 'Model Size:', '899.37 KB']\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035b06b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sr = 16000 # Sampling rate\n",
    "#duration = 5\n",
    "hop_length = 347 # to make time steps 128\n",
    "fmin = 20\n",
    "fmax = sr // 2\n",
    "n_mels = 128\n",
    "n_fft = n_mels * 20\n",
    "\n",
    "def create_dataset(map_to_class,\n",
    "                  NUM_FEATURES):\n",
    "\n",
    "    df = pd.read_csv('./ESC-50-master/meta/esc50.csv')\n",
    "    \n",
    "    category_to_class = {\n",
    "    'dog': 'hayvan',\n",
    "    'chirping_birds': 'hayvan',\n",
    "    'vacuum_cleaner': 'arkaplan', \n",
    "    'thunderstorm': 'arkaplan',\n",
    "    'door_wood_knock': 'arkaplan',\n",
    "    'can_opening': 'arkaplan',\n",
    "    'crow': 'arkaplan',\n",
    "    'clapping': 'insan',\n",
    "    'fireworks': 'arkaplan',\n",
    "    'chainsaw': 'arac',\n",
    "    'airplane': 'arac',\n",
    "    'mouse_click': 'arkaplan',\n",
    "    'pouring_water': 'arkaplan',\n",
    "    'train': 'arac',\n",
    "    'sheep': 'hayvan',\n",
    "    'water_drops': 'arkaplan',\n",
    "    'church_bells': 'arkaplan',\n",
    "    'clock_alarm': 'arkaplan',\n",
    "    'keyboard_typing': 'arkaplan',\n",
    "    'wind': 'arkaplan',\n",
    "    'footsteps': 'insan',\n",
    "    'frog': 'arkaplan',\n",
    "    'cow': 'hayvan',\n",
    "    'brushing_teeth': 'arkaplan',\n",
    "    'car_horn': 'arac',\n",
    "    'crackling_fire': 'arkaplan',\n",
    "    'helicopter': 'arac',\n",
    "    'drinking_sipping': 'arkaplan',\n",
    "    'rain': 'arkaplan',\n",
    "    'insects': 'arkaplan',\n",
    "    'laughing': 'insan',\n",
    "    'hen': 'hayvan',\n",
    "    'engine': 'arac',\n",
    "    'breathing': 'insan',\n",
    "    'crying_baby': 'insan', \n",
    "    'hand_saw': 'arac',\n",
    "    'coughing': 'insan',\n",
    "    'glass_breaking': 'arkaplan',\n",
    "    'snoring' : 'insan',\n",
    "    'toilet_flush': 'arkaplan',\n",
    "    'pig': 'hayvan',\n",
    "    'washing_machine': 'arac',\n",
    "    'clock_tick': 'arkaplan',\n",
    "    'sneezing' : 'insan',\n",
    "    'rooster': 'hayvan',\n",
    "    'sea_waves': 'arkaplan',\n",
    "    'siren': 'arac',\n",
    "    'cat': 'hayvan',\n",
    "    'door_wood_creaks': 'arkaplan',\n",
    "    'crickets': 'arkaplan',\n",
    "    }\n",
    "\n",
    "\n",
    "    if map_to_class:\n",
    "        df['class'] = df['category'].map(category_to_class)\n",
    "    else:\n",
    "        df['class'] = df['category']\n",
    "        \n",
    "    def features_extractor(file_name, NUM_FEATURES):\n",
    "        audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast') \n",
    "        audio_16k = librosa.resample(audio, orig_sr=sample_rate, target_sr=16000)\n",
    "        mfccs_features = librosa.feature.mfcc(y=audio_16k, sr=16000, n_mfcc=NUM_FEATURES)\n",
    "        mfccs_features = mfccs_features.T\n",
    "        \n",
    "        spectrogram = librosa.feature.melspectrogram(audio, \n",
    "                                             sr=16000,\n",
    "                                             n_mels=n_mels,\n",
    "                                             hop_length=hop_length,\n",
    "                                             n_fft=n_fft,\n",
    "                                             fmin=fmin,\n",
    "                                             fmax=fmax)\n",
    "        spectrogram = librosa.power_to_db(spectrogram).astype(np.float32)\n",
    "\n",
    "        dct = scipy.fftpack.dct(audio_16k)\n",
    "        dct_64 = scipy.fftpack.dct(audio_16k, n = 64)\n",
    "        dct_128 = scipy.fftpack.dct(audio_16k, n = 128)\n",
    "        dct_256 = scipy.fftpack.dct(audio_16k, n = 256)\n",
    "        dct_512 = scipy.fftpack.dct(audio_16k, n = 512)\n",
    "        \n",
    "        return mfccs_features, spectrogram.T, dct, dct_64, dct_128, dct_256, dct_512\n",
    "\n",
    "\n",
    "    extracted_features=[]\n",
    "    spectograms=[]\n",
    "    dct_list=[]\n",
    "    dct_64_list=[]\n",
    "    dct_128_list=[]\n",
    "    dct_256_list=[]\n",
    "    dct_512_list=[]\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "\n",
    "        file_name = f\"./ESC-50-master/audio/{row['filename']}\"\n",
    "\n",
    "        data, spectrogram, dct, dct_64, dct_128, dct_256, dct_512 =features_extractor(file_name, NUM_FEATURES)\n",
    "\n",
    "        \n",
    "        extracted_features.append([data, row['class'], row['fold']])\n",
    "        spectograms.append([spectrogram, row['class'], row['fold']])\n",
    "        \n",
    "        #original_features.append(original_data.tolist())\n",
    "        \n",
    "    extracted_features_df=pd.DataFrame(extracted_features,columns=['feature', 'class', 'fold'])\n",
    "    spectograms_df=pd.DataFrame(spectograms,columns=['feature', 'class', 'fold'])\n",
    "\n",
    "\n",
    "    padded_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        extracted_features_df['feature'].tolist(), padding=\"post\")\n",
    "    \n",
    "    padded_inputs_spec = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        spectograms_df['feature'].tolist(), padding=\"post\")\n",
    "\n",
    "\n",
    "    y=np.array(extracted_features_df['class'].tolist())\n",
    "\n",
    "    \n",
    "    return extracted_features_df, spectograms_df, y, padded_inputs, padded_inputs_spec\n",
    "\n",
    "\n",
    "\n",
    "def create_dataset(map_to_class,\n",
    "                  NUM_FEATURES):\n",
    "\n",
    "    df = pd.read_csv('./ESC-50-master/meta/esc50.csv')\n",
    "    \n",
    "    category_to_class = {\n",
    "    'dog': 'hayvan',\n",
    "    'chirping_birds': 'hayvan',\n",
    "    'vacuum_cleaner': 'arkaplan', \n",
    "    'thunderstorm': 'arkaplan',\n",
    "    'door_wood_knock': 'arkaplan',\n",
    "    'can_opening': 'arkaplan',\n",
    "    'crow': 'arkaplan',\n",
    "    'clapping': 'insan',\n",
    "    'fireworks': 'arkaplan',\n",
    "    'chainsaw': 'arac',\n",
    "    'airplane': 'arac',\n",
    "    'mouse_click': 'arkaplan',\n",
    "    'pouring_water': 'arkaplan',\n",
    "    'train': 'arac',\n",
    "    'sheep': 'hayvan',\n",
    "    'water_drops': 'arkaplan',\n",
    "    'church_bells': 'arkaplan',\n",
    "    'clock_alarm': 'arkaplan',\n",
    "    'keyboard_typing': 'arkaplan',\n",
    "    'wind': 'arkaplan',\n",
    "    'footsteps': 'insan',\n",
    "    'frog': 'arkaplan',\n",
    "    'cow': 'hayvan',\n",
    "    'brushing_teeth': 'arkaplan',\n",
    "    'car_horn': 'arac',\n",
    "    'crackling_fire': 'arkaplan',\n",
    "    'helicopter': 'arac',\n",
    "    'drinking_sipping': 'arkaplan',\n",
    "    'rain': 'arkaplan',\n",
    "    'insects': 'arkaplan',\n",
    "    'laughing': 'insan',\n",
    "    'hen': 'hayvan',\n",
    "    'engine': 'arac',\n",
    "    'breathing': 'insan',\n",
    "    'crying_baby': 'insan', \n",
    "    'hand_saw': 'arac',\n",
    "    'coughing': 'insan',\n",
    "    'glass_breaking': 'arkaplan',\n",
    "    'snoring' : 'insan',\n",
    "    'toilet_flush': 'arkaplan',\n",
    "    'pig': 'hayvan',\n",
    "    'washing_machine': 'arac',\n",
    "    'clock_tick': 'arkaplan',\n",
    "    'sneezing' : 'insan',\n",
    "    'rooster': 'hayvan',\n",
    "    'sea_waves': 'arkaplan',\n",
    "    'siren': 'arac',\n",
    "    'cat': 'hayvan',\n",
    "    'door_wood_creaks': 'arkaplan',\n",
    "    'crickets': 'arkaplan',\n",
    "    }\n",
    "\n",
    "    raw_data = extracted_features\n",
    "    if map_to_class:\n",
    "        df['class'] = df['category'].map(category_to_class)\n",
    "    else:\n",
    "        df['class'] = df['category']\n",
    "        \n",
    "    def load_dataset(file_name, NUM_FEATURES):\n",
    "        audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast') \n",
    "        audio_16k = librosa.resample(audio, orig_sr=sample_rate, target_sr=16000)\n",
    "        \n",
    "        return audio_16k\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "\n",
    "        file_name = f\"./ESC-50-master/audio/{row['filename']}\"\n",
    "\n",
    "        data = load_dataset(file_name)\n",
    "\n",
    "        extracted_features.append([data, row['class'], row['fold']])\n",
    "        spectograms.append([spectrogram, row['class'], row['fold']])\n",
    "        \n",
    "        #original_features.append(original_data.tolist())\n",
    "        \n",
    "    extracted_features_df=pd.DataFrame(extracted_features,columns=['feature', 'class', 'fold'])\n",
    "    spectograms_df=pd.DataFrame(spectograms,columns=['feature', 'class', 'fold'])\n",
    "\n",
    "\n",
    "    padded_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        extracted_features_df['feature'].tolist(), padding=\"post\")\n",
    "    \n",
    "    padded_inputs_spec = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        spectograms_df['feature'].tolist(), padding=\"post\")\n",
    "\n",
    "\n",
    "    y=np.array(extracted_features_df['class'].tolist())\n",
    "\n",
    "    \n",
    "    return extracted_features_df, spectograms_df, y, padded_inputs, padded_inputs_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea4bc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#/home/gltkn/Desktop/sekiza/akustik_data/ESC-50-master/audio/1-137-A-32.wav\n",
    "\n",
    "file_name = './ESC-50-master/audio/1-137-A-32.wav'\n",
    "audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast') \n",
    "audio_16k = librosa.resample(audio, orig_sr=sample_rate, target_sr=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd7a1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.fftpack.dct(audio_16k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67c95e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_features_df, spectograms_df, y, padded_inputs, padded_inputs_spec = create_dataset(True, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ff5f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_inputs_spec.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e681400",
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_inputs.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31546e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_features_df['class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c030abde",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cat = tf.keras.utils.to_categorical(extracted_features_df['class'].map(dict(zip(extracted_features_df['class'].unique(), range(4)))).tolist() , num_classes=len(np.unique(y)))\n",
    "y_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c0e8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(img):\n",
    "    '''\n",
    "    Normalizes an array \n",
    "    (subtract mean and divide by standard deviation)\n",
    "    '''\n",
    "    eps = 0.001\n",
    "    if np.std(img) != 0:\n",
    "        img = (img - np.mean(img)) / np.std(img)\n",
    "    else:\n",
    "        img = (img - np.mean(img)) / eps\n",
    "    return img\n",
    "\n",
    "\n",
    "normalized_padded_inputs = normalize(padded_inputs)\n",
    "normalized_padded_inputs_spec = normalize(padded_inputs_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93cb5998",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = np.where(extracted_features_df['fold']<4)[0]\n",
    "val = np.where(extracted_features_df['fold']==4)[0]\n",
    "test = np.where(extracted_features_df['fold']==5)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b794ee53",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "import tensorflow as tf\n",
    "    \n",
    "from sklearn.metrics import *\n",
    "bestacc = 0\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import LSTM, Dense, Input, Conv1D, AveragePooling1D, Attention\n",
    "from tensorflow.keras.optimizers import *\n",
    "        \n",
    "\n",
    "\n",
    "for l in [50,100,200]:\n",
    "  for d in [32]:\n",
    "   for bs in [4,16]:\n",
    "    for lr in [0.001]:\n",
    "       for transpose in [ False]:\n",
    "        for bn in [False]:\n",
    "         for mitr in range(4):\n",
    "          for ump in [True,False]:\n",
    "            for split_name, split_df in [\n",
    "                                        ('mfcc_normalized', normalized_padded_inputs),\n",
    "                                        ('spectrogram_normalized', normalized_padded_inputs_spec),\n",
    "                                        ]:\n",
    "\n",
    "\n",
    "                x_train = split_df[tr]\n",
    "                x_val = split_df[val]\n",
    "                x_test = split_df[test]\n",
    "\n",
    "                y_train = y_cat[tr]\n",
    "                y_val = y_cat[val]\n",
    "                y_test = y_cat[test]\n",
    "    \n",
    "\n",
    "                if transpose:\n",
    "                    x_train_copy = x_train.reshape((x_train.shape[0], x_train.shape[2], x_train.shape[1]))\n",
    "                    x_val_copy = x_val.reshape((x_val.shape[0], x_val.shape[2], x_val.shape[1]))\n",
    "                    x_test_copy = x_test.reshape((x_test.shape[0], x_test.shape[2], x_test.shape[1]))\n",
    "\n",
    "                else:\n",
    "                    x_train_copy = x_train.copy()\n",
    "                    x_val_copy = x_val.copy()\n",
    "                    x_test_copy = x_test.copy()\n",
    "\n",
    "                tf.random.set_seed(3)\n",
    "\n",
    "                \n",
    "                inp = Input(shape=(x_train_copy.shape[1],x_train_copy.shape[2]))\n",
    "\n",
    "                if mitr == 0:\n",
    "                    #x = Conv1D(25, kernel_size=2)(inp)\n",
    "                    x = Conv1D(64,5,strides=1,activation=\"relu\",)(inp)\n",
    "                    x = Attention()([x,x])\n",
    "                    if ump:\n",
    "                        x = MaxPooling1D()(x)\n",
    "                    x = Bidirectional(LSTM(l))(x)\n",
    "                    x = Dense(d,activation='relu')(x)\n",
    "                    x = Dense(d,activation='relu')(x)\n",
    "\n",
    "                elif mitr == 1:\n",
    "                    #x = Conv1D(25, kernel_size=2)(inp)\n",
    "                    x = LSTM(l,return_sequences= True )(inp)\n",
    "                    if ump:\n",
    "                        x = MaxPooling1D()(x)\n",
    "                    x = LSTM(l)(x)\n",
    "                    x = Dense(d,activation='relu')(x)\n",
    "                    x = Dense(d,activation='relu')(x)\n",
    "                    \n",
    "                elif mitr == 2:\n",
    "                    #x = Conv1D(25, kernel_size=2)(inp)\n",
    "                    x = Bidirectional(LSTM(l,return_sequences= True ))(inp)\n",
    "                    if ump:\n",
    "                        x = MaxPooling1D()(x)\n",
    "                    x = Bidirectional(LSTM(l))(x)\n",
    "                    x = Dense(d,activation='relu')(x)\n",
    "                    x = Dense(d,activation='relu')(x)\n",
    "                    \n",
    "                elif mitr == 3:\n",
    "                    #x = Conv1D(25, kernel_size=2)(inp)\n",
    "                    x = Bidirectional(LSTM(l,return_sequences= True ))(inp)\n",
    "                    x = Attention()([x,x])\n",
    "                    if ump:\n",
    "                        x = MaxPooling1D()(x)\n",
    "                    x = Bidirectional(LSTM(l))(x)\n",
    "                    x = Dense(d,activation='relu')(x)\n",
    "                    x = Dense(d,activation='relu')(x)\n",
    "\n",
    "                    \n",
    "                out = Dense(y_cat.shape[1],activation='softmax')(x)\n",
    "\n",
    "                model = Model(inputs=inp, outputs=out)\n",
    "\n",
    "                es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, verbose = 0)\n",
    "\n",
    "                optimizer = tf.keras.optimizers.Adam(learning_rate = lr)\n",
    "                model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "                history = model.fit(x_train_copy, y_train, batch_size=bs, epochs=500, validation_data=(x_val_copy, y_val), verbose =0, callbacks = [es])\n",
    "\n",
    "\n",
    "                pred_train = model.predict(x_train_copy)\n",
    "                pred_val = model.predict(x_val_copy)\n",
    "                pred_test = model.predict(x_test_copy)\n",
    "\n",
    "                curacc_train = accuracy_score(np.argsort(y_train,axis=1)[:,-1], np.argsort(pred_train,axis=1)[:,-1])\n",
    "                curacc_val = accuracy_score(np.argsort(y_val,axis=1)[:,-1], np.argsort(pred_val,axis=1)[:,-1])\n",
    "                curacc_test = accuracy_score(np.argsort(y_test,axis=1)[:,-1], np.argsort(pred_test,axis=1)[:,-1])\n",
    "\n",
    "                model.save('my_model.h5')\n",
    "\n",
    "                import os\n",
    "\n",
    "                def get_size(path):\n",
    "                    size = os.path.getsize(path)\n",
    "                    if size < 1024:\n",
    "                        return f\"{size} bytes\"\n",
    "                    elif size < 1024*1024:\n",
    "                        return f\"{round(size/1024, 2)} KB\"\n",
    "                    elif size < 1024*1024*1024:\n",
    "                        return f\"{round(size/(1024*1024), 2)} MB\"\n",
    "                    elif size < 1024*1024*1024*1024:\n",
    "                        return f\"{round(size/(1024*1024*1024), 2)} GB\"\n",
    "\n",
    "                \n",
    "\n",
    "                print('______')\n",
    "                print(['Train:', curacc_train, 'Val:', curacc_val, 'Test:', curacc_test])\n",
    "                cm_val = confusion_matrix(np.argmax(y_val,axis=1), np.argmax(pred_val,axis=1))\n",
    "                #print(cm_val)\n",
    "\n",
    "                cm_test = confusion_matrix(np.argmax(y_test,axis=1), np.argmax(pred_test,axis=1))\n",
    "                #print(cm_test)\n",
    "                print([split_name, mitr, ump, l, d, bs, lr , outact, transpose, bn, 'Model Size:', get_size('my_model.h5')])\n",
    "   \n",
    "'''\n",
    "['Train:', 0.6758333333333333, 'Val:', 0.5725, 'Test:', 0.59]\n",
    "['mfcc_normalized', 0, True, 50, 32, 4, 0.001, 'softmax', False, False, 'Model Size:', '899.37 KB']\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd626ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dropout,Embedding,GlobalMaxPooling1D, MaxPooling1D, Add, Flatten\n",
    "\n",
    "\n",
    "inp = Input(shape=(x_train_copy.shape[1],x_train_copy.shape[2]))\n",
    "#x = Conv1D(25, kernel_size=2)(inp)\n",
    "x = LSTM(l,return_sequences= True )(inp)\n",
    "x = Dropout(do)(x)\n",
    "x = MaxPooling1D()(x)\n",
    "x = LSTM(l)(x)\n",
    "x = Dropout(do)(x)\n",
    "x = Dense(d,activation='relu')(x)\n",
    "x = Dropout(do)(x)\n",
    "x = Dense(d,activation='relu')(x)\n",
    "x = Dropout(do)(x)\n",
    "out = Dense(y_cat.shape[1],activation=outact)(x)\n",
    "model = Model(inputs=inp, outputs=out)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb8f8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_model.h5')\n",
    "\n",
    "import os\n",
    "\n",
    "def get_size(path):\n",
    "    size = os.path.getsize(path)\n",
    "    if size < 1024:\n",
    "        return f\"{size} bytes\"\n",
    "    elif size < 1024*1024:\n",
    "        return f\"{round(size/1024, 2)} KB\"\n",
    "    elif size < 1024*1024*1024:\n",
    "        return f\"{round(size/(1024*1024), 2)} MB\"\n",
    "    elif size < 1024*1024*1024*1024:\n",
    "        return f\"{round(size/(1024*1024*1024), 2)} GB\"\n",
    "    \n",
    "get_size('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fcd3cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea8b992",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pred_val = model.predict(x_val)\n",
    "pred_test = model.predict(x_test)\n",
    "\n",
    "curacc_val = accuracy_score(np.argsort(y_val,axis=1)[:,-1], np.argsort(pred_val,axis=1)[:,-1])\n",
    "curacc_test = accuracy_score(np.argsort(y_test,axis=1)[:,-1], np.argsort(pred_test,axis=1)[:,-1])\n",
    "\n",
    "cm_val = confusion_matrix(np.argmax(y_val,axis=1), np.argmax(pred_val,axis=1))\n",
    "print(cm_val)\n",
    "\n",
    "cm_test = confusion_matrix(np.argmax(y_test,axis=1), np.argmax(pred_test,axis=1))\n",
    "print(cm_test)\n",
    "print([curacc_val, curacc_test, mtc, bs, d ,l ,NUM_FEATURES])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4578f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_val = confusion_matrix(np.argmax(y_val,axis=1), np.argmax(pred_val,axis=1))\n",
    "print(cm_val)\n",
    "\n",
    "cm_test = confusion_matrix(np.argmax(y_test,axis=1), np.argmax(pred_test,axis=1))\n",
    "print(cm_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f95cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1eda7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    import itertools\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    fig = plt.figure(figsize=(10,7))\n",
    "    \n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a52fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "class_names = dict(zip(range(len(labelencoder.classes_)),labelencoder.classes_))\n",
    "\n",
    "y_true = np.argsort(y,axis=1)[:,-1]\n",
    "y_pred = np.argsort(ypreds,axis=1)[:,-1]\n",
    "\n",
    "y_true\n",
    "y_pred\n",
    "\n",
    "cnf_matrix = confusion_matrix([class_names[x] for x in y_true],\n",
    "                 [class_names[x] for x in y_pred],\n",
    "                 labels=labelencoder.classes_)\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=labelencoder.classes_,\n",
    "                      title='Confusion matrix, without normalization')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
