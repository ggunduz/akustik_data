{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2cdb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import normalize\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import LSTM, Dense, BatchNormalization, Bidirectional, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035b06b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset():\n",
    "\n",
    "    df = pd.read_csv('./ESC-50-master/meta/esc50.csv')\n",
    "    \n",
    "    category_to_class = {\n",
    "    'dog': 'hayvan',\n",
    "    'chirping_birds': 'hayvan',\n",
    "    'vacuum_cleaner': 'arkaplan', \n",
    "    'thunderstorm': 'arkaplan',\n",
    "    'door_wood_knock': 'arkaplan',\n",
    "    'can_opening': 'arkaplan',\n",
    "    'crow': 'arkaplan',\n",
    "    'clapping': 'insan',\n",
    "    'fireworks': 'arkaplan',\n",
    "    'chainsaw': 'arac',\n",
    "    'airplane': 'arac',\n",
    "    'mouse_click': 'arkaplan',\n",
    "    'pouring_water': 'arkaplan',\n",
    "    'train': 'arac',\n",
    "    'sheep': 'hayvan',\n",
    "    'water_drops': 'arkaplan',\n",
    "    'church_bells': 'arkaplan',\n",
    "    'clock_alarm': 'arkaplan',\n",
    "    'keyboard_typing': 'arkaplan',\n",
    "    'wind': 'arkaplan',\n",
    "    'footsteps': 'insan',\n",
    "    'frog': 'arkaplan',\n",
    "    'cow': 'hayvan',\n",
    "    'brushing_teeth': 'arkaplan',\n",
    "    'car_horn': 'arac',\n",
    "    'crackling_fire': 'arkaplan',\n",
    "    'helicopter': 'arac',\n",
    "    'drinking_sipping': 'arkaplan',\n",
    "    'rain': 'arkaplan',\n",
    "    'insects': 'arkaplan',\n",
    "    'laughing': 'insan',\n",
    "    'hen': 'hayvan',\n",
    "    'engine': 'arac',\n",
    "    'breathing': 'insan',\n",
    "    'crying_baby': 'insan', \n",
    "    'hand_saw': 'arac',\n",
    "    'coughing': 'insan',\n",
    "    'glass_breaking': 'arkaplan',\n",
    "    'snoring' : 'insan',\n",
    "    'toilet_flush': 'arkaplan',\n",
    "    'pig': 'hayvan',\n",
    "    'washing_machine': 'arac',\n",
    "    'clock_tick': 'arkaplan',\n",
    "    'sneezing' : 'insan',\n",
    "    'rooster': 'hayvan',\n",
    "    'sea_waves': 'arkaplan',\n",
    "    'siren': 'arac',\n",
    "    'cat': 'hayvan',\n",
    "    'door_wood_creaks': 'arkaplan',\n",
    "    'crickets': 'arkaplan',\n",
    "    }\n",
    "\n",
    "    raw_data = []\n",
    "    df['class'] = df['category'].map(category_to_class)\n",
    "\n",
    "    def load_dataset(file_name):\n",
    "        audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast', sr = None) \n",
    "        audio_16k = librosa.resample(audio, orig_sr=sample_rate, target_sr=16000)\n",
    "        \n",
    "        return audio_16k.tolist()\n",
    "\n",
    "    raw_data_list = []\n",
    "    for _, row in df.iterrows():\n",
    "\n",
    "        file_name = f\"./ESC-50-master/audio/{row['filename']}\"\n",
    "\n",
    "        data = load_dataset(file_name)\n",
    "\n",
    "        raw_data_list.append([data, row['class'], row['fold']])\n",
    "        \n",
    "    raw_data_list = pd.DataFrame(raw_data_list, columns = ['feature', 'class', 'fold'])\n",
    "\n",
    "    y = np.array(raw_data_list['class'].tolist())\n",
    "    \n",
    "    return raw_data_list, y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67c95e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_list, y = create_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b63b01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(raw_data_list['feature'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c74219",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=(8,4))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(data[500])\n",
    "plt.show()\n",
    "fig = plt.figure(figsize=(8,4))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(data[800])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31546e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_list['class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c030abde",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cat = tf.keras.utils.to_categorical(raw_data_list['class'].map(dict(zip(raw_data_list['class'].unique(), range(4)))).tolist() , num_classes=len(np.unique(y)))\n",
    "y_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c0e8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(img):\n",
    "    '''\n",
    "    Normalizes an array \n",
    "    (subtract mean and divide by standard deviation)\n",
    "    '''\n",
    "    eps = 0.001\n",
    "    if np.std(img) != 0:\n",
    "        img = (img - np.mean(img)) / np.std(img)\n",
    "    else:\n",
    "        img = (img - np.mean(img)) / eps\n",
    "    return img\n",
    "\n",
    "\n",
    "normalized_data = normalize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50c71e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=(8,4))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(normalized_data[500])\n",
    "plt.show()\n",
    "fig = plt.figure(figsize=(8,4))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(normalized_data[800])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93cb5998",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = np.where(raw_data_list['fold']<4)[0]\n",
    "val = np.where(raw_data_list['fold']==4)[0]\n",
    "test = np.where(raw_data_list['fold']==5)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b794ee53",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "import tensorflow as tf\n",
    "    \n",
    "from sklearn.metrics import *\n",
    "bestacc = 0\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import LSTM, Dense, Input, Conv1D, AveragePooling1D, Attention, GlobalAveragePooling1D\n",
    "from tensorflow.keras.optimizers import *\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "#for k in [-9, -6, -5, -4, -3, -2, -1, 0, 1, 2, 3]:\n",
    "for k in [-5, -4, -3, -2, -1, 0, 1, 2, 3]:\n",
    " for df in [data, normalized_data]:\n",
    "    \n",
    "\n",
    "                y_train = y_cat[tr]\n",
    "                y_val = y_cat[val]\n",
    "                y_test = y_cat[test]\n",
    "    \n",
    "                x_train_copy = df[tr].copy()\n",
    "                x_val_copy = df[val].copy()\n",
    "                x_test_copy = df[test].copy()\n",
    "\n",
    "                tf.random.set_seed(3)\n",
    "                \n",
    "\n",
    "            \n",
    "                \n",
    "                if k == -9:\n",
    "                    \n",
    "                    x_train_copy = librosa.feature.poly_features(y=x_train_copy, sr=16000)\n",
    "                    x_val_copy = librosa.feature.poly_features(y=x_val_copy, sr=16000)\n",
    "                    x_test_copy = librosa.feature.poly_features(y=x_test_copy, sr=16000)\n",
    "                    \n",
    "                       \n",
    "                    x_train_copy = x_train_copy.reshape((x_train_copy.shape[0], x_train_copy.shape[2], x_train_copy.shape[1],))\n",
    "                    x_val_copy = x_val_copy.reshape((x_val_copy.shape[0], x_val_copy.shape[2], x_val_copy.shape[1],))\n",
    "                    x_test_copy = x_test_copy.reshape((x_test_copy.shape[0], x_test_copy.shape[2], x_test_copy.shape[1],))\n",
    "\n",
    "                \n",
    "             \n",
    "                if k == -6:\n",
    "                    \n",
    "                    x_train_copy = librosa.feature.spectral_contrast(y=x_train_copy, sr=16000)\n",
    "                    x_val_copy = librosa.feature.spectral_contrast(y=x_val_copy, sr=16000)\n",
    "                    x_test_copy = librosa.feature.spectral_contrast(y=x_test_copy, sr=16000)\n",
    "                    \n",
    "                       \n",
    "                    x_train_copy = x_train_copy.reshape((x_train_copy.shape[0], x_train_copy.shape[2], x_train_copy.shape[1],))\n",
    "                    x_val_copy = x_val_copy.reshape((x_val_copy.shape[0], x_val_copy.shape[2], x_val_copy.shape[1],))\n",
    "                    x_test_copy = x_test_copy.reshape((x_test_copy.shape[0], x_test_copy.shape[2], x_test_copy.shape[1],))\n",
    "\n",
    "\n",
    "          \n",
    "                if k == -4:\n",
    "                    \n",
    "                    x_train_copy = librosa.feature.spectral_centroid(y=x_train_copy, sr=16000)\n",
    "                    x_val_copy = librosa.feature.spectral_centroid(y=x_val_copy, sr=16000)\n",
    "                    x_test_copy = librosa.feature.spectral_centroid(y=x_test_copy, sr=16000)\n",
    "                    \n",
    "                       \n",
    "                    x_train_copy = x_train_copy.reshape((x_train_copy.shape[0], x_train_copy.shape[2], x_train_copy.shape[1],))\n",
    "                    x_val_copy = x_val_copy.reshape((x_val_copy.shape[0], x_val_copy.shape[2], x_val_copy.shape[1],))\n",
    "                    x_test_copy = x_test_copy.reshape((x_test_copy.shape[0], x_test_copy.shape[2], x_test_copy.shape[1],))\n",
    "\n",
    "\n",
    "                if k == -3:\n",
    "                    \n",
    "                    x_train_copy = librosa.feature.chroma_cens(y=x_train_copy, sr=16000, power=2)\n",
    "                    x_val_copy = librosa.feature.chroma_cens(y=x_val_copy, sr=16000, power=2)\n",
    "                    x_test_copy = librosa.feature.chroma_cens(y=x_test_copy, sr=16000, power=2)\n",
    "                    \n",
    "                       \n",
    "                    x_train_copy = x_train_copy.reshape((x_train_copy.shape[0], x_train_copy.shape[2], x_train_copy.shape[1],))\n",
    "                    x_val_copy = x_val_copy.reshape((x_val_copy.shape[0], x_val_copy.shape[2], x_val_copy.shape[1],))\n",
    "                    x_test_copy = x_test_copy.reshape((x_test_copy.shape[0], x_test_copy.shape[2], x_test_copy.shape[1],))\n",
    "\n",
    "\n",
    "                if k == -2:\n",
    "                    \n",
    "                    x_train_copy = librosa.feature.chroma_cqt(y=x_train_copy, sr=16000, power=2)\n",
    "                    x_val_copy = librosa.feature.chroma_cqt(y=x_val_copy, sr=16000, power=2)\n",
    "                    x_test_copy = librosa.feature.chroma_cqt(y=x_test_copy, sr=16000, power=2)\n",
    "                    \n",
    "                       \n",
    "                    x_train_copy = x_train_copy.reshape((x_train_copy.shape[0], x_train_copy.shape[2], x_train_copy.shape[1],))\n",
    "                    x_val_copy = x_val_copy.reshape((x_val_copy.shape[0], x_val_copy.shape[2], x_val_copy.shape[1],))\n",
    "                    x_test_copy = x_test_copy.reshape((x_test_copy.shape[0], x_test_copy.shape[2], x_test_copy.shape[1],))\n",
    "\n",
    "\n",
    "\n",
    "                if k == -1:\n",
    "                    \n",
    "                    x_train_copy = librosa.feature.chroma_stft(y=x_train_copy, sr=16000, power=2)\n",
    "                    x_val_copy = librosa.feature.chroma_stft(y=x_val_copy, sr=16000, power=2)\n",
    "                    x_test_copy = librosa.feature.chroma_stft(y=x_test_copy, sr=16000, power=2)\n",
    "                    \n",
    "                       \n",
    "                    x_train_copy = x_train_copy.reshape((x_train_copy.shape[0], x_train_copy.shape[2], x_train_copy.shape[1],))\n",
    "                    x_val_copy = x_val_copy.reshape((x_val_copy.shape[0], x_val_copy.shape[2], x_val_copy.shape[1],))\n",
    "                    x_test_copy = x_test_copy.reshape((x_test_copy.shape[0], x_test_copy.shape[2], x_test_copy.shape[1],))\n",
    "\n",
    "\n",
    "                if k == 0:\n",
    "                    \n",
    "                    power = librosa.feature.melspectrogram(y=x_train_copy, sr=16000, power=2)\n",
    "                    x_train_copy = librosa.core.power_to_db(power)\n",
    "                    \n",
    "                    \n",
    "                    power = librosa.feature.melspectrogram(y=x_val_copy, sr=16000, power=2)\n",
    "                    x_val_copy = librosa.core.power_to_db(power)\n",
    "                    \n",
    "                    \n",
    "                    power = librosa.feature.melspectrogram(y=x_test_copy, sr=16000, power=2)\n",
    "                    x_test_copy = librosa.core.power_to_db(power)\n",
    "                    \n",
    "                       \n",
    "                    x_train_copy = x_train_copy.reshape((x_train_copy.shape[0], x_train_copy.shape[2], x_train_copy.shape[1],))\n",
    "                    x_val_copy = x_val_copy.reshape((x_val_copy.shape[0], x_val_copy.shape[2], x_val_copy.shape[1],))\n",
    "                    x_test_copy = x_test_copy.reshape((x_test_copy.shape[0], x_test_copy.shape[2], x_test_copy.shape[1],))\n",
    "\n",
    "\n",
    "                elif k == 1:\n",
    "                    \n",
    "                    x_train_copy = librosa.feature.melspectrogram(y=x_train_copy, sr=16000, power=2)\n",
    "                    x_val_copy = librosa.feature.melspectrogram(y=x_val_copy, sr=16000, power=2)\n",
    "                    x_test_copy = librosa.feature.melspectrogram(y=x_test_copy, sr=16000, power=2)\n",
    "                    \n",
    "                       \n",
    "                    x_train_copy = x_train_copy.reshape((x_train_copy.shape[0], x_train_copy.shape[2], x_train_copy.shape[1],))\n",
    "                    x_val_copy = x_val_copy.reshape((x_val_copy.shape[0], x_val_copy.shape[2], x_val_copy.shape[1],))\n",
    "                    x_test_copy = x_test_copy.reshape((x_test_copy.shape[0], x_test_copy.shape[2], x_test_copy.shape[1],))\n",
    "\n",
    "                    \n",
    "                elif k == 2:\n",
    "                    \n",
    "                    x_train_copy =  scipy.fftpack.dct(x_train_copy, n=512)\n",
    "                    x_val_copy =  scipy.fftpack.dct(x_val_copy, n=512)\n",
    "                    x_test_copy =  scipy.fftpack.dct(x_test_copy, n=512)\n",
    "                    \n",
    "                  \n",
    "                elif k == 3:\n",
    "                    \n",
    "                    x_train_copy = librosa.feature.mfcc(x_train_copy, n_mfcc=64)\n",
    "                    x_val_copy = librosa.feature.mfcc(x_val_copy, n_mfcc=64)\n",
    "                    x_test_copy = librosa.feature.mfcc(x_test_copy, n_mfcc=64)\n",
    "                    \n",
    "                    x_train_copy = x_train_copy.reshape((x_train_copy.shape[0], x_train_copy.shape[2], x_train_copy.shape[1],))\n",
    "                    x_val_copy = x_val_copy.reshape((x_val_copy.shape[0], x_val_copy.shape[2], x_val_copy.shape[1],))\n",
    "                    x_test_copy = x_test_copy.reshape((x_test_copy.shape[0], x_test_copy.shape[2], x_test_copy.shape[1],))\n",
    "\n",
    "                if len(x_train_copy.shape) == 2:\n",
    "                    \n",
    "                    x_train_copy = x_train_copy.reshape((x_train_copy.shape[0], x_train_copy.shape[1], 1))\n",
    "                    x_val_copy = x_val_copy.reshape((x_val_copy.shape[0], x_val_copy.shape[1], 1))\n",
    "                    x_test_copy = x_test_copy.reshape((x_test_copy.shape[0], x_test_copy.shape[1], 1))\n",
    "\n",
    "                    \n",
    "                inp = Input(shape=(x_train_copy.shape[1],x_train_copy.shape[2]))\n",
    "                x = LSTM(64, return_sequences = True)(inp)\n",
    "                x = Dropout(0.1)(x)\n",
    "                x = LSTM(32)(x)\n",
    "                x = Dropout(0.1)(x)\n",
    "                x = Dense(32, activation = 'relu')(x)\n",
    "                x = Dropout(0.1)(x)\n",
    "                out = Dense(y_cat.shape[1],activation='softmax')(x)\n",
    "\n",
    "                model = Model(inputs=inp, outputs=out)\n",
    "\n",
    "                es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, verbose = 0)\n",
    "\n",
    "                optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001)\n",
    "                model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "                history = model.fit(x_train_copy, y_train, batch_size=32, epochs=500, validation_data=(x_val_copy, y_val), verbose =1, callbacks = [es])\n",
    "\n",
    "\n",
    "                pred_train = model.predict(x_train_copy)\n",
    "                pred_val = model.predict(x_val_copy)\n",
    "                pred_test = model.predict(x_test_copy)\n",
    "\n",
    "                curacc_train = accuracy_score(np.argsort(y_train,axis=1)[:,-1], np.argsort(pred_train,axis=1)[:,-1])\n",
    "                curacc_val = accuracy_score(np.argsort(y_val,axis=1)[:,-1], np.argsort(pred_val,axis=1)[:,-1])\n",
    "                curacc_test = accuracy_score(np.argsort(y_test,axis=1)[:,-1], np.argsort(pred_test,axis=1)[:,-1])\n",
    "\n",
    "                model.save('my_model.h5')\n",
    "\n",
    "                import os\n",
    "\n",
    "                def get_size(path):\n",
    "                    size = os.path.getsize(path)\n",
    "                    if size < 1024:\n",
    "                        return f\"{size} bytes\"\n",
    "                    elif size < 1024*1024:\n",
    "                        return f\"{round(size/1024, 2)} KB\"\n",
    "                    elif size < 1024*1024*1024:\n",
    "                        return f\"{round(size/(1024*1024), 2)} MB\"\n",
    "                    elif size < 1024*1024*1024*1024:\n",
    "                        return f\"{round(size/(1024*1024*1024), 2)} GB\"\n",
    "\n",
    "                \n",
    "\n",
    "                print('______')\n",
    "                print(['Train:', curacc_train, 'Val:', curacc_val, 'Test:', curacc_test])\n",
    "                #cm_val = confusion_matrix(np.argmax(y_val,axis=1), np.argmax(pred_val,axis=1))\n",
    "                #print(cm_val)\n",
    "\n",
    "                #cm_test = confusion_matrix(np.argmax(y_test,axis=1), np.argmax(pred_test,axis=1))\n",
    "                #print(cm_test)\n",
    "                #print([split_name, mitr, ump, l, d, bs, lr , outact, transpose, bn, 'Model Size:', get_size('my_model.h5')])\n",
    "   \n",
    "'''\n",
    "['Train:', 0.6758333333333333, 'Val:', 0.5725, 'Test:', 0.59]\n",
    "['mfcc_normalized', 0, True, 50, 32, 4, 0.001, 'softmax', False, False, 'Model Size:', '899.37 KB']\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f3dd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d82286",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd626ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dropout,Embedding,GlobalMaxPooling1D, MaxPooling1D, Add, Flatten\n",
    "\n",
    "\n",
    "inp = Input(shape=(x_train_copy.shape[1],x_train_copy.shape[2]))\n",
    "#x = Conv1D(25, kernel_size=2)(inp)\n",
    "x = LSTM(l,return_sequences= True )(inp)\n",
    "x = Dropout(do)(x)\n",
    "x = MaxPooling1D()(x)\n",
    "x = LSTM(l)(x)\n",
    "x = Dropout(do)(x)\n",
    "x = Dense(d,activation='relu')(x)\n",
    "x = Dropout(do)(x)\n",
    "x = Dense(d,activation='relu')(x)\n",
    "x = Dropout(do)(x)\n",
    "out = Dense(y_cat.shape[1],activation=outact)(x)\n",
    "model = Model(inputs=inp, outputs=out)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb8f8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_model.h5')\n",
    "\n",
    "import os\n",
    "\n",
    "def get_size(path):\n",
    "    size = os.path.getsize(path)\n",
    "    if size < 1024:\n",
    "        return f\"{size} bytes\"\n",
    "    elif size < 1024*1024:\n",
    "        return f\"{round(size/1024, 2)} KB\"\n",
    "    elif size < 1024*1024*1024:\n",
    "        return f\"{round(size/(1024*1024), 2)} MB\"\n",
    "    elif size < 1024*1024*1024*1024:\n",
    "        return f\"{round(size/(1024*1024*1024), 2)} GB\"\n",
    "    \n",
    "get_size('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fcd3cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea8b992",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pred_val = model.predict(x_val)\n",
    "pred_test = model.predict(x_test)\n",
    "\n",
    "curacc_val = accuracy_score(np.argsort(y_val,axis=1)[:,-1], np.argsort(pred_val,axis=1)[:,-1])\n",
    "curacc_test = accuracy_score(np.argsort(y_test,axis=1)[:,-1], np.argsort(pred_test,axis=1)[:,-1])\n",
    "\n",
    "cm_val = confusion_matrix(np.argmax(y_val,axis=1), np.argmax(pred_val,axis=1))\n",
    "print(cm_val)\n",
    "\n",
    "cm_test = confusion_matrix(np.argmax(y_test,axis=1), np.argmax(pred_test,axis=1))\n",
    "print(cm_test)\n",
    "print([curacc_val, curacc_test, mtc, bs, d ,l ,NUM_FEATURES])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4578f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_val = confusion_matrix(np.argmax(y_val,axis=1), np.argmax(pred_val,axis=1))\n",
    "print(cm_val)\n",
    "\n",
    "cm_test = confusion_matrix(np.argmax(y_test,axis=1), np.argmax(pred_test,axis=1))\n",
    "print(cm_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f95cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1eda7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    import itertools\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    fig = plt.figure(figsize=(10,7))\n",
    "    \n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a52fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "class_names = dict(zip(range(len(labelencoder.classes_)),labelencoder.classes_))\n",
    "\n",
    "y_true = np.argsort(y,axis=1)[:,-1]\n",
    "y_pred = np.argsort(ypreds,axis=1)[:,-1]\n",
    "\n",
    "y_true\n",
    "y_pred\n",
    "\n",
    "cnf_matrix = confusion_matrix([class_names[x] for x in y_true],\n",
    "                 [class_names[x] for x in y_pred],\n",
    "                 labels=labelencoder.classes_)\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=labelencoder.classes_,\n",
    "                      title='Confusion matrix, without normalization')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
